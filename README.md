# TechnicalTest
Technical test Unity XR Development for AIST

Project Information:
This project was created in Unity 2022.3.4f1. Using OpenXR for the VR capabilities. The project is only compatible with Windws systems.

This project is comprehended by two scenes, each for a task.
In Task 1:
  In the hierarchy you will only find:
  -Main camera
  -Directional Light
  -Manager

  The instructions were:
  For this test, you will integrate an external C# library to dynamically display information (e.g.,
force arrows at a given point in space). The goal here is to implement a simple project with the
following characteristics:
1. Create an external function that simulates the information generated by a force sensor:
 X/Y/Z force reading
 6d position of the sensor in the world
2. Generate a translucent arrow at the position given by this dummy force sensor library, the
arrow should start at the position given by the library and use the force reading for its
direction. Furthermore, its color should change smoothly based on the magnitude/norm of
the force reading (e.g., green for low values and red for high values).

3. Create a scene that includes multiple arrows of this nature connected to different sensors,
the settings for these elements should be available in a single place and affect all sensors
(e.g., color selection and magnitude threshold).

To use:
In the manager, you will find the SensorManager. Where the number of sensor to be created can be set. In this same GameObject, you will be able to set the thresholds and colors for the sensor values. 
Initially 10 sensors are being created with random positions, rotations and forces.
This manager will instantiate a prefab called Arrow, which contains the sensor being simulated. 



In Task 2:
  The hierarchy is comprehended by:
  -A directional light
  -XR Interaction Manager
  -XR Origin
  -EventSystem
  -Plane, named Ground
  -XR Canvas
  -2D Canvas

  In this Scene the followed instructions were:
  
  1. Create a GUI having two buttons labeled as “Left” and “Right” and a text box. Its behavior should be such that when the “Left” button gets triggered, the text “Left” appears within the text box, and the same with the other button.
3. It should be possible to operate the GUI by a) voice, b) by mouse, c) by pressing the keys
“L” (for “Left”) or “R” (for “Right”), and d) by using a VR controller.
4. Furthermore, the GUI should not appear unless it has been activated in some way
(voice/keyboard/button input).

Instructions to use: 

The GUI doesn't appear unless activated, to activate the GUI the user must say "Menu" or press any of the following keys on the keyboard "L", "R", "M".
When the GUI is activated 2 GUI are set to visible. One for XR intex¡raction and one to facilitate interaction with the mouse.
When the buttons are clicked the Text in the screen will change to "Left" or "Right".
The GUI can be interacted with by using: mouse, L and R keys on the keyboard, XR controllers, and voice by saying "left" and "right"
To deactivate the menu, press the "M" key, or saying "Off".
